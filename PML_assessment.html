<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Rodrigo Parizotto" />


<title>Practical Machine Learning model on Weight Lifting Exercise Dataset</title>

<script src="PML_assessment_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="PML_assessment_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="PML_assessment_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="PML_assessment_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="PML_assessment_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="PML_assessment_files/navigation-1.1/tabsets.js"></script>
<link href="PML_assessment_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="PML_assessment_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Practical Machine Learning model on Weight Lifting Exercise Dataset</h1>
<h4 class="author"><em>Rodrigo Parizotto</em></h4>
<h4 class="date"><em>Dec 22th, 2018</em></h4>

</div>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The goal of this project is to create a machine learning model and predict the manner in which a few people did Weight Lifting Exercise. The output variable is “Classe”.</p>
<p>The training data for this project are available here:</p>
<p><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv" class="uri">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv</a></p>
<p>The test data are available here:</p>
<p><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv" class="uri">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv</a></p>
</div>
<div id="load-data" class="section level2">
<h2>Load data</h2>
<p>Let’s load libraries and datasets already downloaded on local path</p>
<pre class="r"><code>suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
suppressMessages(library(caret))
#if (!file.exists(&quot;pml-training.csv&quot;)) setwd(&#39;C:/POC/Git/Practical_ML_PeerAssessment1&#39;) #setting according to user environment
dftrain_orig &lt;- read.table(&quot;pml-training.csv&quot;, sep=&#39;,&#39;,quote=&#39;&quot;&#39;, header = TRUE)
dftest_orig &lt;- read.table(&quot;pml-testing.csv&quot;, sep=&#39;,&#39;,quote=&#39;&quot;&#39;, header = TRUE)</code></pre>
<div id="good-columns-identification" class="section level3">
<h3>Good Columns Identification</h3>
<p>Let’s check the near zero variance on columns and remove the columns. They might cause issues on training the models.</p>
<pre class="r"><code>nsv &lt;- nearZeroVar(dftrain_orig[,names(dftrain_orig) != &#39;classe&#39;],saveMetrics=TRUE)
nsv[nsv$nzv == TRUE,]</code></pre>
<pre><code>##                          freqRatio percentUnique zeroVar  nzv
## new_window                47.33005    0.01019264   FALSE TRUE
## kurtosis_roll_belt      1921.60000    2.02323922   FALSE TRUE
## kurtosis_picth_belt      600.50000    1.61553358   FALSE TRUE
## kurtosis_yaw_belt         47.33005    0.01019264   FALSE TRUE
## skewness_roll_belt      2135.11111    2.01304658   FALSE TRUE
## skewness_roll_belt.1     600.50000    1.72255631   FALSE TRUE
## skewness_yaw_belt         47.33005    0.01019264   FALSE TRUE
## max_yaw_belt             640.53333    0.34654979   FALSE TRUE
## min_yaw_belt             640.53333    0.34654979   FALSE TRUE
## amplitude_yaw_belt        50.04167    0.02038528   FALSE TRUE
## avg_roll_arm              77.00000    1.68178575   FALSE TRUE
## stddev_roll_arm           77.00000    1.68178575   FALSE TRUE
## var_roll_arm              77.00000    1.68178575   FALSE TRUE
## avg_pitch_arm             77.00000    1.68178575   FALSE TRUE
## stddev_pitch_arm          77.00000    1.68178575   FALSE TRUE
## var_pitch_arm             77.00000    1.68178575   FALSE TRUE
## avg_yaw_arm               77.00000    1.68178575   FALSE TRUE
## stddev_yaw_arm            80.00000    1.66649679   FALSE TRUE
## var_yaw_arm               80.00000    1.66649679   FALSE TRUE
## kurtosis_roll_arm        246.35897    1.68178575   FALSE TRUE
## kurtosis_picth_arm       240.20000    1.67159311   FALSE TRUE
## kurtosis_yaw_arm        1746.90909    2.01304658   FALSE TRUE
## skewness_roll_arm        249.55844    1.68688207   FALSE TRUE
## skewness_pitch_arm       240.20000    1.67159311   FALSE TRUE
## skewness_yaw_arm        1746.90909    2.01304658   FALSE TRUE
## max_roll_arm              25.66667    1.47793293   FALSE TRUE
## min_roll_arm              19.25000    1.41677709   FALSE TRUE
## min_pitch_arm             19.25000    1.47793293   FALSE TRUE
## amplitude_roll_arm        25.66667    1.55947406   FALSE TRUE
## amplitude_pitch_arm       20.00000    1.49831821   FALSE TRUE
## kurtosis_roll_dumbbell  3843.20000    2.02833554   FALSE TRUE
## kurtosis_picth_dumbbell 9608.00000    2.04362450   FALSE TRUE
## kurtosis_yaw_dumbbell     47.33005    0.01019264   FALSE TRUE
## skewness_roll_dumbbell  4804.00000    2.04362450   FALSE TRUE
## skewness_pitch_dumbbell 9608.00000    2.04872082   FALSE TRUE
## skewness_yaw_dumbbell     47.33005    0.01019264   FALSE TRUE
## max_yaw_dumbbell         960.80000    0.37203139   FALSE TRUE
## min_yaw_dumbbell         960.80000    0.37203139   FALSE TRUE
## amplitude_yaw_dumbbell    47.92020    0.01528896   FALSE TRUE
## kurtosis_roll_forearm    228.76190    1.64101519   FALSE TRUE
## kurtosis_picth_forearm   226.07059    1.64611151   FALSE TRUE
## kurtosis_yaw_forearm      47.33005    0.01019264   FALSE TRUE
## skewness_roll_forearm    231.51807    1.64611151   FALSE TRUE
## skewness_pitch_forearm   226.07059    1.62572623   FALSE TRUE
## skewness_yaw_forearm      47.33005    0.01019264   FALSE TRUE
## max_roll_forearm          27.66667    1.38110284   FALSE TRUE
## max_yaw_forearm          228.76190    0.22933442   FALSE TRUE
## min_roll_forearm          27.66667    1.37091020   FALSE TRUE
## min_yaw_forearm          228.76190    0.22933442   FALSE TRUE
## amplitude_roll_forearm    20.75000    1.49322189   FALSE TRUE
## amplitude_yaw_forearm     59.67702    0.01528896   FALSE TRUE
## avg_roll_forearm          27.66667    1.64101519   FALSE TRUE
## stddev_roll_forearm       87.00000    1.63082255   FALSE TRUE
## var_roll_forearm          87.00000    1.63082255   FALSE TRUE
## avg_pitch_forearm         83.00000    1.65120783   FALSE TRUE
## stddev_pitch_forearm      41.50000    1.64611151   FALSE TRUE
## var_pitch_forearm         83.00000    1.65120783   FALSE TRUE
## avg_yaw_forearm           83.00000    1.65120783   FALSE TRUE
## stddev_yaw_forearm        85.00000    1.64101519   FALSE TRUE
## var_yaw_forearm           85.00000    1.64101519   FALSE TRUE</code></pre>
<p>Selecting only the good columns</p>
<pre class="r"><code>df0 &lt;- dftrain_orig %&gt;% 
  select(num_window:total_accel_belt, gyros_belt_x:total_accel_arm, gyros_arm_x:magnet_arm_z, roll_dumbbell:yaw_dumbbell, total_accel_dumbbell, gyros_dumbbell_x:yaw_forearm, total_accel_forearm, gyros_forearm_x:magnet_forearm_z, classe)

columns &lt;- names(df0)
columns &lt;- columns[! columns %in% c(&#39;classe&#39;)]

dftest20samples &lt;- dftest_orig %&gt;%
  select(columns)</code></pre>
<p>Checking nearZeroVar again</p>
<pre class="r"><code>nsv &lt;- nearZeroVar(df0[,names(df0) != &#39;classe&#39;],saveMetrics=TRUE)
nsv[nsv$nzv == TRUE,]</code></pre>
<pre><code>## [1] freqRatio     percentUnique zeroVar       nzv          
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<p>The results of nearZeroVar function applied to df0 confirm that we removed bad columns.</p>
</div>
</div>
<div id="data-spliting" class="section level2">
<h2>Data spliting</h2>
<p>Let’s use 80% of data for training the model and 20% of data to calculate the expected out of sample error</p>
<pre class="r"><code>set.seed(12)
train_index = createDataPartition(df0$classe, p=0.8, list = FALSE)
df_train &lt;- df0[train_index,]
df_test &lt;- df0[-train_index,]</code></pre>
</div>
<div id="exploratory-analysis" class="section level2">
<h2>Exploratory analysis</h2>
<p>Simple plot to check the distribution</p>
<p><img src="PML_assessment_files/figure-html/classe-1.png" /><!-- --></p>
</div>
<div id="model" class="section level2">
<h2>Model</h2>
<p>Let’s use trainControl function to setup Cross Validation (CV). The preProcess funtion will center, scale and fill empty models before training the model. For simplicity, we can compare just 2 models</p>
<pre class="r"><code>#cvCtrl &lt;- trainControl(method = &quot;repeatedcv&quot;, repeats = 3)
#cvCtrl &lt;- trainControl(method = &quot;cv&quot;)
cvCtrl &lt;- trainControl(method = &quot;cv&quot;,
                       number = 5 ,
                       verboseIter = FALSE
                       )
set.seed(12)
model1 &lt;- train(classe ~ ., data = df_train,
                preProcess=c(&quot;center&quot;,&quot;scale&quot;,&quot;knnImpute&quot;),
                method = &quot;rpart&quot;,
                tuneLength = 30,
                trControl = cvCtrl,
                na.action = na.pass)

set.seed(12)
model2 &lt;- train(classe ~ ., data = df_train,
                preProcess=c(&quot;center&quot;,&quot;scale&quot;,&quot;knnImpute&quot;),
                method = &quot;svmLinear&quot;,
                tuneLength = 10,
                trControl = cvCtrl,
                na.action = na.pass)

set.seed(12)
model3 &lt;- train(classe ~ ., data = df_train, 
                 preProcess=c(&quot;center&quot;,&quot;scale&quot;,&quot;knnImpute&quot;),
                 method = &quot;gbm&quot;, 
                 trControl = cvCtrl,
                 ## This last option is actually one
                 ## for gbm() that passes through
                 verbose = FALSE)</code></pre>
</div>
<div id="prediction" class="section level2">
<h2>Prediction</h2>
<p>Model 1 Results</p>
<pre class="r"><code>pred1 &lt;- predict(model1, newdata = df_test)
cf1 &lt;- confusionMatrix(df_test$classe, pred1)
cf1</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1037   31   14   30    4
##          B   86  572   61   13   27
##          C    9   53  560   42   20
##          D   53   35   34  508   13
##          E   13   24   40   54  590
## 
## Overall Statistics
##                                           
##                Accuracy : 0.8328          
##                  95% CI : (0.8207, 0.8443)
##     No Information Rate : 0.3054          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.788           
##  Mcnemar&#39;s Test P-Value : 2.55e-13        
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.8656   0.8000   0.7898   0.7852   0.9021
## Specificity            0.9710   0.9417   0.9614   0.9588   0.9599
## Pos Pred Value         0.9292   0.7536   0.8187   0.7900   0.8183
## Neg Pred Value         0.9426   0.9548   0.9540   0.9576   0.9800
## Prevalence             0.3054   0.1823   0.1807   0.1649   0.1667
## Detection Rate         0.2643   0.1458   0.1427   0.1295   0.1504
## Detection Prevalence   0.2845   0.1935   0.1744   0.1639   0.1838
## Balanced Accuracy      0.9183   0.8709   0.8756   0.8720   0.9310</code></pre>
<p>Note that the <code>echo = FALSE</code> parameter was added to the code chunk to prevent printing of the R code that generated the plot.</p>
<p>Model 2 Results</p>
<pre class="r"><code>pred2 &lt;- predict(model2, newdata = df_test)
cf2 &lt;- confusionMatrix(df_test$classe, pred2)
cf2</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1026   31   18   35    6
##          B   87  557   50   10   55
##          C   55   51  546   15   17
##          D   40   26   77  473   27
##          E   49   79   43   40  510
## 
## Overall Statistics
##                                           
##                Accuracy : 0.7933          
##                  95% CI : (0.7803, 0.8058)
##     No Information Rate : 0.3204          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.7372          
##  Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.8162   0.7487   0.7439   0.8255   0.8293
## Specificity            0.9662   0.9365   0.9567   0.9493   0.9362
## Pos Pred Value         0.9194   0.7339   0.7982   0.7356   0.7074
## Neg Pred Value         0.9177   0.9409   0.9420   0.9695   0.9672
## Prevalence             0.3204   0.1897   0.1871   0.1461   0.1568
## Detection Rate         0.2615   0.1420   0.1392   0.1206   0.1300
## Detection Prevalence   0.2845   0.1935   0.1744   0.1639   0.1838
## Balanced Accuracy      0.8912   0.8426   0.8503   0.8874   0.8827</code></pre>
<p>Model 3 Results</p>
<pre class="r"><code>pred3 &lt;- predict(model3, newdata = df_test)
cf3 &lt;- confusionMatrix(df_test$classe, pred3)
cf3</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1113    3    0    0    0
##          B    6  745    7    1    0
##          C    0    6  673    4    1
##          D    0    4    9  629    1
##          E    0    1    1    4  715
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9878         
##                  95% CI : (0.9838, 0.991)
##     No Information Rate : 0.2852         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.9845         
##  Mcnemar&#39;s Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9946   0.9816   0.9754   0.9859   0.9972
## Specificity            0.9989   0.9956   0.9966   0.9957   0.9981
## Pos Pred Value         0.9973   0.9816   0.9839   0.9782   0.9917
## Neg Pred Value         0.9979   0.9956   0.9948   0.9973   0.9994
## Prevalence             0.2852   0.1935   0.1759   0.1626   0.1828
## Detection Rate         0.2837   0.1899   0.1716   0.1603   0.1823
## Detection Prevalence   0.2845   0.1935   0.1744   0.1639   0.1838
## Balanced Accuracy      0.9968   0.9886   0.9860   0.9908   0.9977</code></pre>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>Model 3 shows the best Expected Accuracy, around 98% on testing data (20% split). Let’s use the Model 3 to predict the 20 samples in dftest20samples.</p>
<pre class="r"><code>predict20 &lt;- predict(model3, newdata = dftest20samples)
data.frame(sample=1:20,classe=predict20)</code></pre>
<pre><code>##    sample classe
## 1       1      B
## 2       2      A
## 3       3      B
## 4       4      A
## 5       5      A
## 6       6      E
## 7       7      D
## 8       8      B
## 9       9      A
## 10     10      A
## 11     11      B
## 12     12      C
## 13     13      B
## 14     14      A
## 15     15      E
## 16     16      E
## 17     17      A
## 18     18      B
## 19     19      B
## 20     20      B</code></pre>
</div>
<div id="section" class="section level1">
<h1></h1>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
